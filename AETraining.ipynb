{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3667f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change path to your location\n",
    "pathToSimData=\"/Users/dnoonan/Work/AIinPixel/simulated ptychography dataset\"\n",
    "\n",
    "with h5py.File(f\"{pathToSimData}/data_cell_phase_n2e7.h5\", \"r\") as f:\n",
    "    data = f['exchange/data'][...]\n",
    "with h5py.File(f\"{pathToSimData}/data_cell_phase_n2e7_ref.h5\", \"r\") as f:\n",
    "    data_ref = f['exchange/data'][...]\n",
    "    \n",
    "data = data[0,:,36-16:36+16,36-16:36+16].real**2\n",
    "data_ref = data_ref[0,:,36-16:36+16,36-16:36+16].real**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6aa06e",
   "metadata": {},
   "source": [
    "Setup simple autoencoder\n",
    "\n",
    "examples can be found here: https://keras.io/examples/vision/autoencoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9990bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, MaxPooling2D, Dense, Conv2D, Conv2DTranspose, Reshape, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is a 32x32 image\n",
    "inputs = Input(shape=(32,32,1),name='input')\n",
    "\n",
    "#add a convolutional layer, 8 filters with 3x3 kernel size\n",
    "x = Conv2D(filters=8,\n",
    "           kernel_size=(3,3),   \n",
    "           activation='relu',\n",
    "           padding='same',\n",
    "           name='convLayer'\n",
    "          )(inputs)\n",
    "\n",
    "x = Flatten(name='flattenLayer')(x)\n",
    "\n",
    "encodedLayer = Dense(64,\n",
    "                     activation='relu',\n",
    "                     name='denseLayer')(x)\n",
    "\n",
    "d = Dense(32*32*8,\n",
    "          name='decoderDense')(encodedLayer)\n",
    "\n",
    "d = Reshape((32,32,8))(d)\n",
    "\n",
    "d = Conv2DTranspose(8,(3,3),activation=\"relu\", padding=\"same\")(d)\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='decoded')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418df7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf91d4",
   "metadata": {},
   "source": [
    "Preprocessing:\n",
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a949ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNorm = data / data.sum(axis=(1,2)).reshape(-1,1,1)\n",
    "dataNorm_ref = data_ref / data_ref.sum(axis=(1,2)).reshape(-1,1,1)\n",
    "\n",
    "dataNorm.shape=(-1,32,32,1)\n",
    "dataNorm_ref.shape=(-1,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(dataNorm_ref,dataNorm_ref,\n",
    "                          epochs=2,\n",
    "                          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31375b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNorm_Out = autoencoder.predict(dataNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot\n",
    "fig,ax = plt.subplots(4,2,figsize=(8,15))\n",
    "#ax = ax.flatten()\n",
    "#get 4 random images\n",
    "N = np.random.choice(np.arange(dataNorm.shape[0]),4)\n",
    "for i in range(4):\n",
    "    im = ax[i][0].imshow(dataNorm[N[i]],norm=LogNorm())  \n",
    "    fig.colorbar(im,ax=ax[i][0])\n",
    "    im = ax[i][1].imshow(dataNorm_Out[N[i]],norm=LogNorm())\n",
    "    fig.colorbar(im,ax=ax[i][1])\n",
    "#     ax[i][1].colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac1161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
